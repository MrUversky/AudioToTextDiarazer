# AudioToTextDiarazer

Инструмент для извлечения аудио из видео, распознавания речи и диаризации (определения говорящих).

## Возможности

- Извлечение аудио из видеофайлов
- Распознавание речи с помощью моделей Whisper
- Диаризация (определение говорящих) с использованием PyAnnote или резервного метода
- Поддержка работы на CPU или GPU
- Настройка параметров распознавания и диаризации

## Использование в Google Colab

1. Загрузите видеофайл в Google Colab
2. Укажите путь к файлу в параметре `INPUT_MEDIA`
3. Настройте параметры обработки (начало/конец, диаризация, язык и т.д.)
4. Запустите код

## Установка локально

```bash
# Клонирование репозитория
git clone https://github.com/your-username/AudioToTextDiarazer.git
cd AudioToTextDiarazer

# Установка зависимостей
pip install faster-whisper whisperx

# Для диаризации потребуются дополнительные зависимости
pip install speechbrain scikit-learn librosa soundfile
```

## Настройка параметров

```python
# Основные параметры
INPUT_MEDIA = "путь_к_файлу.mp4"  # Путь к видео/аудиофайлу
START_MIN = None  # Начальное время в минутах
END_MIN = None    # Конечное время в минутах
DIARIZE = False   # True для определения говорящих
NUM_SPEAKERS = 2  # Количество говорящих
LANG = "ru"       # Язык распознавания

# Настройки ASR (распознавания речи)
PREFER_GPU_ASR = True
FORCE_CPU_ASR = True  # True для работы на CPU
```

## Требования

- Python 3.7+
- FFmpeg
- GPU с CUDA (опционально)
- Доступ к Hugging Face для PyAnnote (требуется для продвинутой диаризации)

## Результаты

После выполнения скрипт создает следующие файлы:
- JSON файл с распознанным текстом и метками времени
- SRT файл с субтитрами
- SRT файл с указанием говорящих (если включена диаризация)
